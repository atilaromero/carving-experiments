{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 - Train a model for each dataset category, comparing it to random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atila.alr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import models\n",
    "import report\n",
    "import block_sampler\n",
    "import batch_encoder\n",
    "from dataset import Dataset\n",
    "from report import Reporter2\n",
    "from trainer import Trainer, TrainResults\n",
    "from batch_encoder import Dataset, one_hot\n",
    "from block_sampler import count_sectors, BlockSamplerByFile, RandomSampler\n",
    "from batch_encoder import xs_encoder_8bits_11, BatchEncoder, xs_encoder_one_hot\n",
    "from filter_random import gen_rndchk_models, evaluate_rnd_model, filter_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Activation, TimeDistributed, Flatten, Dot, Softmax, Lambda, RepeatVector, Multiply, Permute, Reshape, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_folder='govdocs1/sample200'\n",
    "minimum=200\n",
    "maximum=200\n",
    "result_dir = 'results/4.3-randomness'\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawset = Dataset.new_from_folders(raw_dataset_folder).filter_min_max(minimum, maximum)\n",
    "rawset = rawset.filter(lambda x: rawset.category_from(x) not in ['text', 'unk'])\n",
    "rawset.rebuild_categories()\n",
    "rawtset, rawvset = rawset.rnd_split_fraction_by_category(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(classes, len_byte_vector):\n",
    "    last = l0 = Input(shape=(512,len_byte_vector))\n",
    "    last = Conv1D(classes, (32,), strides=1)(last)\n",
    "    last = MaxPooling1D(pool_size=481, strides=1)(last)\n",
    "    last = Flatten()(last)\n",
    "    last = Activation('softmax')(last)\n",
    "    name = sys._getframe().f_code.co_name\n",
    "    model = tf.keras.Model([l0], last, name=name)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['binary_accuracy', 'categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatSampler:\n",
    "    def __init__(self, model, blksampler, cat):\n",
    "        self.model = model\n",
    "        self.blksampler = blksampler\n",
    "        self.dataset = blksampler.dataset\n",
    "        self.cat = cat\n",
    "\n",
    "    def __iter__(self):\n",
    "        fails=0\n",
    "        tbenc = iter(BatchEncoder(self.blksampler, 100,\n",
    "                                  xs_encoder='one_hot'))\n",
    "        while True:\n",
    "            blks = next(tbenc)[0]\n",
    "            predict = self.model.predict(blks)\n",
    "            predict = np.argmax(predict, axis=-1)\n",
    "            blks = [x for x,y in zip(blks, predict) if y == self.cat]\n",
    "            if len(blks) == 0:\n",
    "                fails += 1\n",
    "                if fails > 1000:\n",
    "                    raise Exception(\"all blocks seems to be the wrong kind\")\n",
    "                continue\n",
    "            fails=0\n",
    "            for blk in blks:\n",
    "                yield block_sampler.BlockInstance(np.argmax(blk, axis=-1), self.blksampler.dataset.categories[self.cat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThrSampler:\n",
    "    def __init__(self, model, blksampler, threshold, cat):\n",
    "        self.model = model\n",
    "        self.blksampler = blksampler\n",
    "        self.dataset = blksampler.dataset\n",
    "        self.threshold = threshold\n",
    "        self.cat = cat\n",
    "\n",
    "    def __iter__(self):\n",
    "        fails=0\n",
    "        tbenc = iter(BatchEncoder(self.blksampler, 100,\n",
    "                                  xs_encoder='one_hot'))\n",
    "        while True:\n",
    "            blks = next(tbenc)[0]\n",
    "            predict = self.model.predict(blks)\n",
    "            predict = predict[:,0]-predict[:,1]\n",
    "            blks = [x for x,y in zip(blks, predict) if y > self.threshold]\n",
    "            if len(blks) == 0:\n",
    "                fails += 1\n",
    "                if fails > 1000:\n",
    "                    raise Exception(\"all blocks seems to be the wrong kind\")\n",
    "                continue\n",
    "            fails=0\n",
    "            for blk in blks:\n",
    "                yield block_sampler.BlockInstance(np.argmax(blk, axis=-1), self.cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=28\n",
    "patience=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from block_sampler import BlockSamplerByCategory\n",
    "from batch_encoder import BatchEncoder\n",
    "from collections import namedtuple\n",
    "import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "\n",
    "TrainResults = namedtuple(\n",
    "    'TrainResults', ['model', 'history', 'metrics', 'elapsed'])\n",
    "\n",
    "class RandomTrainer:\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 xs_encoder='one_hot',\n",
    "                 validation_steps=steps_per_epoch,\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 epochs=10000000,\n",
    "                 max_seconds=None,\n",
    "                 batch_size=100,\n",
    "                 min_delta=1e-03,\n",
    "                 patience=patience):\n",
    "        self.model = model\n",
    "        self.xs_encoder = xs_encoder\n",
    "        self.validation_steps = validation_steps\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.epochs = epochs\n",
    "        self.max_seconds = max_seconds\n",
    "        self.batch_size = batch_size\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "\n",
    "    def train(self, tset, vset, previous_model=None, previous_model2=None):\n",
    "        tsampler = BlockSamplerByFile(tset)\n",
    "        if previous_model:\n",
    "            tsampler = CatSampler(previous_model, tsampler, 0)\n",
    "        if previous_model2:\n",
    "            tsampler = CatSampler(previous_model2, tsampler, 0)\n",
    "        trsampler = RandomSampler(tsampler, rnd_cat='zzz', not_rnd_cat=tset.categories[0])\n",
    "        tbenc = BatchEncoder(trsampler, self.batch_size,\n",
    "                             xs_encoder=self.xs_encoder)\n",
    "\n",
    "        vsampler = BlockSamplerByFile(vset)\n",
    "        if previous_model:\n",
    "            vsampler = CatSampler(previous_model, vsampler, 0)\n",
    "        if previous_model2:\n",
    "            vsampler = CatSampler(previous_model2, vsampler, 0)\n",
    "        vrsampler = RandomSampler(vsampler, rnd_cat='zzz', not_rnd_cat=vset.categories[0])\n",
    "        vbenc = BatchEncoder(vrsampler, self.batch_size,\n",
    "                             xs_encoder=self.xs_encoder)\n",
    "\n",
    "        return self._train(tbenc,vbenc)\n",
    "\n",
    "    def _train(self, tbenc, vbenc):\n",
    "        model = self.model\n",
    "\n",
    "        timeIt = callbacks.TimeIt()\n",
    "\n",
    "        history = model.fit_generator(iter(tbenc),\n",
    "                                      validation_data=iter(vbenc),\n",
    "                                      validation_steps=self.validation_steps,\n",
    "                                      steps_per_epoch=self.steps_per_epoch,\n",
    "                                      epochs=self.epochs,\n",
    "                                      verbose=0,\n",
    "                                      callbacks=[\n",
    "            timeIt,\n",
    "            # callbacks.SaveModel(os.path.join(result_dir, model.name + '.h5')),\n",
    "#             callbacks.TimeLimit(self.max_seconds),\n",
    "            EarlyStopping(monitor='val_categorical_accuracy',\n",
    "                          min_delta=self.min_delta, patience=self.patience),\n",
    "            # TensorBoard(\n",
    "            #     log_dir=os.path.join(log_dir, model.name),\n",
    "            #     # update_freq=3100,\n",
    "            # ),\n",
    "#             LambdaCallback(on_epoch_end = lambda epoch, logs: print(logs['val_categorical_accuracy'])),\n",
    "        ],\n",
    "            use_multiprocessing=False,\n",
    "            workers=0,\n",
    "        )\n",
    "        return TrainResults(\n",
    "            model=model,\n",
    "            history=history,\n",
    "            metrics=['val_binary_accuracy', 'val_categorical_accuracy'],\n",
    "            elapsed=timeIt.elapsed,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndgen(block_instance=False):\n",
    "    while True:\n",
    "        rdata = np.random.randint(0, 256, (100,512), dtype='int')\n",
    "        rdata = one_hot(rdata, 256)\n",
    "        if block_instance:\n",
    "            yield (rdata, np.array([0,1]*100).reshape(100,2))\n",
    "        else:\n",
    "            yield rdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pass1 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "rtf\n",
      "val_acc = 0.99785715 struct_acc= 0.996 rnd_acc= 1.0\n",
      "xls\n",
      "val_acc = 0.9882143 struct_acc= 0.978 rnd_acc= 1.0\n",
      "ps\n",
      "val_acc = 0.9632143 struct_acc= 0.924 rnd_acc= 1.0\n",
      "pdf\n",
      "val_acc = 0.7292857 struct_acc= 0.461 rnd_acc= 0.996\n",
      "doc\n",
      "val_acc = 0.9235714 struct_acc= 0.84 rnd_acc= 1.0\n",
      "dwf\n",
      "val_acc = 0.5921429 struct_acc= 0.355 rnd_acc= 0.857\n",
      "dbase3\n",
      "val_acc = 1.0 struct_acc= 1.0 rnd_acc= 1.0\n",
      "log\n",
      "val_acc = 1.0 struct_acc= 1.0 rnd_acc= 1.0\n",
      "xml\n",
      "val_acc = 0.99892855 struct_acc= 0.998 rnd_acc= 1.0\n",
      "java\n",
      "val_acc = 0.9992857 struct_acc= 1.0 rnd_acc= 1.0\n",
      "png\n",
      "val_acc = 0.6160714 struct_acc= 0.273 rnd_acc= 0.976\n",
      "pptx\n",
      "val_acc = 0.7192857 struct_acc= 0.586 rnd_acc= 0.89\n",
      "jpg\n",
      "val_acc = 0.9142857 struct_acc= 0.887 rnd_acc= 0.957\n",
      "wp\n",
      "val_acc = 0.99392855 struct_acc= 0.992 rnd_acc= 1.0\n",
      "kmz\n",
      "val_acc = 0.7246429 struct_acc= 0.455 rnd_acc= 0.998\n",
      "sql\n",
      "val_acc = 0.99964285 struct_acc= 0.999 rnd_acc= 1.0\n",
      "gz\n",
      "val_acc = 0.61 struct_acc= 0.32 rnd_acc= 0.872\n",
      "txt\n",
      "val_acc = 1.0 struct_acc= 1.0 rnd_acc= 1.0\n",
      "ppt\n",
      "val_acc = 0.73071426 struct_acc= 0.472 rnd_acc= 0.997\n",
      "hlp\n",
      "val_acc = 1.0 struct_acc= 1.0 rnd_acc= 1.0\n",
      "swf\n",
      "val_acc = 0.6992857 struct_acc= 0.405 rnd_acc= 0.976\n",
      "html\n",
      "val_acc = 0.9992857 struct_acc= 0.999 rnd_acc= 1.0\n",
      "csv\n",
      "val_acc = 0.99964285 struct_acc= 0.999 rnd_acc= 1.0\n",
      "kml\n",
      "val_acc = 1.0 struct_acc= 1.0 rnd_acc= 1.0\n",
      "eps\n",
      "val_acc = 0.99 struct_acc= 0.983 rnd_acc= 1.0\n",
      "f\n",
      "val_acc = 0.995 struct_acc= 0.99 rnd_acc= 1.0\n",
      "gif\n",
      "val_acc = 0.7196429 struct_acc= 0.425 rnd_acc= 0.991\n",
      "pps\n",
      "val_acc = 0.7425 struct_acc= 0.546 rnd_acc= 0.985\n"
     ]
    }
   ],
   "source": [
    "r = Reporter2(result_dir + \"/pass1.tsv\")\n",
    "by_categoryT = rawtset.by_category()\n",
    "by_categoryV = rawvset.by_category()\n",
    "for cat in by_categoryT.keys():\n",
    "    tset = by_categoryT[cat]\n",
    "    vset = by_categoryV[cat]\n",
    "    tset.rebuild_categories(categories=[cat, 'zzz'])\n",
    "    vset.rebuild_categories(categories=[cat, 'zzz'])\n",
    "    model = CM(2, 256)\n",
    "    print(cat)\n",
    "    result = RandomTrainer(\n",
    "        model,\n",
    "        batch_size=100,\n",
    "        steps_per_epoch=28,\n",
    "        validation_steps=28,\n",
    "        patience=10,\n",
    "    ).train(tset, vset)\n",
    "    val_acc = result.history.history['val_categorical_accuracy'][-1]\n",
    "    \n",
    "    vsampler = BlockSamplerByFile(vset)\n",
    "    vbenc = BatchEncoder(vsampler, 100,xs_encoder='one_hot')\n",
    "    struct_acc = model.evaluate_generator(iter(vbenc), steps=10)[-1]\n",
    "    \n",
    "    rnd_acc = model.evaluate_generator(rndgen(True), steps=10)[-1]\n",
    "    \n",
    "    print('val_acc =', val_acc, 'struct_acc=', struct_acc, 'rnd_acc=', rnd_acc)\n",
    "    r.line(category=cat,\n",
    "           val_acc=val_acc,\n",
    "           struct_acc=struct_acc,\n",
    "           rnd_acc=rnd_acc,\n",
    "           **report.report_elapsed(**result._asdict()),\n",
    "           **report.report_epochs(**result._asdict()),\n",
    "          )\n",
    "    h5_path = os.path.join(result_dir, '%s_pass1.h5' % cat)\n",
    "    tf.keras.Model.save(model, h5_path)\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>struct_acc</th>\n",
       "      <th>rnd_acc</th>\n",
       "      <th>Time</th>\n",
       "      <th>Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>dwf</td>\n",
       "      <td>0.592143</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.857</td>\n",
       "      <td>12m04s</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>gz</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.872</td>\n",
       "      <td>17m23s</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>png</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.976</td>\n",
       "      <td>15m34s</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>swf</td>\n",
       "      <td>0.699286</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.976</td>\n",
       "      <td>26m12s</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>pptx</td>\n",
       "      <td>0.719286</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.890</td>\n",
       "      <td>20m24s</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>gif</td>\n",
       "      <td>0.719643</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.991</td>\n",
       "      <td>37m27s</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>kmz</td>\n",
       "      <td>0.724643</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.998</td>\n",
       "      <td>15m07s</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0.729286</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.996</td>\n",
       "      <td>30m37s</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ppt</td>\n",
       "      <td>0.730714</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.997</td>\n",
       "      <td>40m21s</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>pps</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.985</td>\n",
       "      <td>31m23s</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.957</td>\n",
       "      <td>33m04s</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>doc</td>\n",
       "      <td>0.923571</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9m02s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ps</td>\n",
       "      <td>0.963214</td>\n",
       "      <td>0.924</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10m00s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xls</td>\n",
       "      <td>0.988214</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.000</td>\n",
       "      <td>18m34s</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>eps</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "      <td>27m06s</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>wp</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m42s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>f</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9m00s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rtf</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9m43s</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>xml</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9m07s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>java</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m51s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>html</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m56s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>csv</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m46s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>sql</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m56s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>txt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m59s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>hlp</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m59s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>log</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m52s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>kml</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m47s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>dbase3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8m48s</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category   val_acc  struct_acc  rnd_acc    Time  Epochs\n",
       "5       dwf  0.592143       0.355    0.857  12m04s      15\n",
       "16       gz  0.610000       0.320    0.872  17m23s      21\n",
       "10      png  0.616071       0.273    0.976  15m34s      19\n",
       "20      swf  0.699286       0.405    0.976  26m12s      32\n",
       "11     pptx  0.719286       0.586    0.890  20m24s      23\n",
       "26      gif  0.719643       0.425    0.991  37m27s      47\n",
       "14      kmz  0.724643       0.455    0.998  15m07s      19\n",
       "3       pdf  0.729286       0.461    0.996  30m37s      37\n",
       "18      ppt  0.730714       0.472    0.997  40m21s      49\n",
       "27      pps  0.742500       0.546    0.985  31m23s      40\n",
       "12      jpg  0.914286       0.887    0.957  33m04s      42\n",
       "4       doc  0.923571       0.840    1.000   9m02s      11\n",
       "2        ps  0.963214       0.924    1.000  10m00s      11\n",
       "1       xls  0.988214       0.978    1.000  18m34s      24\n",
       "24      eps  0.990000       0.983    1.000  27m06s      34\n",
       "13       wp  0.993929       0.992    1.000   8m42s      11\n",
       "25        f  0.995000       0.990    1.000   9m00s      11\n",
       "0       rtf  0.997857       0.996    1.000   9m43s      12\n",
       "8       xml  0.998929       0.998    1.000   9m07s      11\n",
       "9      java  0.999286       1.000    1.000   8m51s      11\n",
       "21     html  0.999286       0.999    1.000   8m56s      11\n",
       "22      csv  0.999643       0.999    1.000   8m46s      11\n",
       "15      sql  0.999643       0.999    1.000   8m56s      11\n",
       "17      txt  1.000000       1.000    1.000   8m59s      11\n",
       "19      hlp  1.000000       1.000    1.000   8m59s      11\n",
       "7       log  1.000000       1.000    1.000   8m52s      11\n",
       "23      kml  1.000000       1.000    1.000   8m47s      11\n",
       "6    dbase3  1.000000       1.000    1.000   8m48s      11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(result_dir + '/pass1.tsv', sep='\\t')\n",
    "data = data.sort_values('val_acc')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot.bar('category', ['val_acc'], figsize=(12,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pass2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/atila.alr/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "ps\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ef1b13e15484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mvsampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThrSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvsampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mvbenc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvsampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxs_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'one_hot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mstruct_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvbenc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mrnd_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrndgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m   def predict_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;34m'Keras requires a thread-safe generator when '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             '`use_multiprocessing=False, workers > 1`. ')\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m   \"\"\"\n\u001b[0;32m--> 828\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Sync/codebase/src/github.com/atilaromero/randomness-experiments/batch_encoder.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Sync/codebase/src/github.com/atilaromero/randomness-experiments/batch_encoder.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-63d82e9b3ad9>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mblks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbenc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mblks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# Setup work for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;31m# Reset the state of loss metric wrappers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3069\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1096\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1099\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "if os.path.exists(result_dir + \"/pass2.tsv\"):\n",
    "    os.remove(result_dir + \"/pass2.tsv\")\n",
    "r = Reporter2(result_dir + \"/pass2.tsv\")\n",
    "by_categoryT = rawtset.by_category()\n",
    "by_categoryV = rawvset.by_category()\n",
    "threshold=0.5\n",
    "for cat in by_categoryT.keys():\n",
    "    tset = by_categoryT[cat]\n",
    "    vset = by_categoryV[cat]\n",
    "    tset.rebuild_categories(categories=[cat, 'zzz'])\n",
    "    vset.rebuild_categories(categories=[cat, 'zzz'])\n",
    "    if data.set_index('category').loc[cat].val_acc > 0.98:\n",
    "        continue\n",
    "    previous_model = tf.keras.models.load_model(result_dir + '/%s_pass1.h5' % cat)\n",
    "    model = CM(2, 256)\n",
    "    print(cat)\n",
    "    batch_size = 100\n",
    "    tsampler = BlockSamplerByFile(tset)\n",
    "    tsampler = ThrSampler(previous_model, tsampler, threshold, cat)\n",
    "    tsampler = RandomSampler(tsampler, rnd_cat='zzz', not_rnd_cat=tset.categories[0])\n",
    "    tbenc = BatchEncoder(tsampler, batch_size,\n",
    "                         xs_encoder='one_hot')\n",
    "\n",
    "    vsampler = BlockSamplerByFile(vset)\n",
    "    vsampler = ThrSampler(previous_model, vsampler, threshold, cat)\n",
    "    vsampler = RandomSampler(vsampler, rnd_cat='zzz', not_rnd_cat=vset.categories[0])\n",
    "    vbenc = BatchEncoder(vsampler, batch_size,\n",
    "                         xs_encoder='one_hot')\n",
    "\n",
    "    result = RandomTrainer(\n",
    "        model,\n",
    "        batch_size=100,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=steps_per_epoch,\n",
    "        patience=patience,\n",
    "    )._train(tbenc,vbenc)\n",
    "    val_acc = result.history.history['val_categorical_accuracy'][-1]\n",
    "\n",
    "    vsampler = BlockSamplerByFile(vset)\n",
    "    vsampler = ThrSampler(previous_model, vsampler, threshold, cat)\n",
    "    vbenc = BatchEncoder(vsampler, 100,xs_encoder='one_hot')\n",
    "    struct_acc = model.evaluate_generator(iter(vbenc), steps=10)[-1]\n",
    "    \n",
    "    rnd_acc = model.evaluate_generator(rndgen(True), steps=10)[-1]\n",
    "    \n",
    "    print('val_acc =', val_acc, 'struct_acc=', struct_acc, 'rnd_acc=', rnd_acc)\n",
    "    r.line(category=cat,\n",
    "           val_acc=val_acc,\n",
    "           struct_acc=struct_acc,\n",
    "           rnd_acc=rnd_acc,\n",
    "           **report.report_elapsed(**result._asdict()),\n",
    "           **report.report_epochs(**result._asdict()),\n",
    "          )\n",
    "    h5_path = os.path.join(result_dir, '%s_pass2.h5' % cat)\n",
    "    tf.keras.Model.save(model, h5_path)\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pass2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(result_dir + \"/pass2.tsv\", sep='\\t')\n",
    "data2 = data2.sort_values('val_acc')\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.plot.bar('category', ['val_acc'], figsize=(12,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data3 = pd.read_csv(result_dir + \"/pass3.tsv\", sep='\\t')\n",
    "data3 = data3.sort_values('val_acc')\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use models to evaluate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Reporter2(result_dir + \"/evaluate.tsv\")\n",
    "by_category = rawset.by_category()\n",
    "for cat, dataset in by_category.items():\n",
    "    model = tf.keras.models.load_model(result_dir + '/%s_pass1.h5' % cat)\n",
    "    tsampler = BlockSamplerByFile(dataset)\n",
    "    tbenc = BatchEncoder(tsampler,\n",
    "                         batch_size=1000,\n",
    "                         xs_encoder='one_hot')\n",
    "    xs, _ = next(iter(tbenc))\n",
    "    datalen = len(xs)\n",
    "    predict = model.predict(xs, batch_size=100)\n",
    "    predict = np.argmax(predict, axis=-1)   \n",
    "    not_random = len(predict[predict==0])/datalen\n",
    "    \n",
    "    predict = model.predict_generator(rndgen(), steps=10)\n",
    "    predict = np.argmax(predict, axis=-1)   \n",
    "    random = len(predict[predict==1])/datalen\n",
    "    \n",
    "    true_not_random = not_random - (1-not_random)*(1-random)/random\n",
    "    \n",
    "    print(cat, not_random, random, true_not_random )\n",
    "    r.line(cat=cat, not_random=not_random, random=random, true_not_random=true_not_random)\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv(result_dir + \"/evaluate.tsv\", sep='\\t')\n",
    "data3 = data3.sort_values('true_not_random')\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "# plt.grid(linestyle='--', which='minor')\n",
    "ax.bar(data3['cat'], data3['true_not_random'], fill=False)\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.tick_params(labelsize=14)\n",
    "for i in range(28):\n",
    "    cat = rawset.ix_to_cat[i]\n",
    "    v = data3.iloc[i,3]\n",
    "    t = ax.annotate('%0.2f'%v, (i-0.3, v-0.06),fontsize=14)\n",
    "    t.set_rotation(90)\n",
    "# data3.plot.bar('cat', ['not_random'], figsize=(12,4))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.sum(data3['true_not_random'])/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(np.sum(data3['true_not_random'])+(1-0.62))/28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roc pass1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_category = rawset.by_category()\n",
    "cat = 'jpg'\n",
    "dataset = by_category[cat]\n",
    "dataset.rebuild_categories(categories=['jpg', 'zzz'])\n",
    "\n",
    "model = tf.keras.models.load_model(result_dir + '/%s_pass1.h5' % cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsampler = BlockSamplerByFile(dataset)\n",
    "tsampler = RandomSampler(tsampler, rnd_cat='zzz', not_rnd_cat='jpg')\n",
    "\n",
    "tbenc = BatchEncoder(tsampler,\n",
    "                     batch_size=1000,\n",
    "                     xs_encoder='one_hot')\n",
    "xs, ys = next(iter(tbenc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = len(xs)\n",
    "predict = model.predict(xs, batch_size=100)\n",
    "# predict = np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predict[:,0]-predict[:,1]\n",
    "mask = score > 0.9\n",
    "print(len(score[mask]), len(score))\n",
    "fpr, tpr, thresholds = roc_curve(ys[:,0][mask], score[mask])\n",
    "mask = thresholds > 0\n",
    "fpr[mask], tpr[mask], thresholds[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predict[:,0]-predict[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use models to evaluate dataset - using pass2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndgen():\n",
    "    while True:\n",
    "        rdata = np.random.randint(0, 256, (100,512), dtype='int')\n",
    "        rdata = one_hot(rdata, 256)\n",
    "        yield rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(result_dir + \"/evaluate2.tsv\"):\n",
    "    os.remove(result_dir + \"/evaluate2.tsv\")\n",
    "r = Reporter2(result_dir + \"/evaluate2.tsv\")\n",
    "by_category = rawset.by_category()\n",
    "for cat, dataset in by_category.items():\n",
    "    model1 = tf.keras.models.load_model(result_dir + '/%s_pass1.h5' % cat)\n",
    "    tsampler = BlockSamplerByFile(dataset)\n",
    "    tbenc = BatchEncoder(tsampler,\n",
    "                         batch_size=1000,\n",
    "                         xs_encoder='one_hot')\n",
    "    xs, _ = next(iter(tbenc))\n",
    "    datalen = len(xs)\n",
    "    predict = model1.predict(xs, batch_size=100)\n",
    "    predict = np.argmax(predict, axis=-1)\n",
    "\n",
    "    \n",
    "    if os.path.exists(result_dir + '/%s_pass2.h5' % cat):\n",
    "        model2 = tf.keras.models.load_model(result_dir + '/%s_pass2.h5' % cat)\n",
    "        xs = xs[predict==0]\n",
    "        datalen = len(xs)\n",
    "        predict = model2.predict(xs, batch_size=100)\n",
    "        predict = np.argmax(predict, axis=-1)\n",
    "\n",
    "    not_random = len(predict[predict==0])/datalen\n",
    "    \n",
    "    if os.path.exists(result_dir + '/%s_pass2.h5' % cat):\n",
    "        predict = model2.predict_generator(rndgen(), steps=10)\n",
    "    else:\n",
    "        predict = model1.predict_generator(rndgen(), steps=10)\n",
    "    predict = np.argmax(predict, axis=-1)   \n",
    "    random = len(predict[predict==1])/(10*100)\n",
    "    \n",
    "    true_not_random = not_random - (1-not_random)*(1-random)/random\n",
    "    \n",
    "    print(cat, not_random, random, true_not_random )\n",
    "    r.line(cat=cat, not_random=not_random, random=random, true_not_random=true_not_random)\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load evaluation data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv(result_dir + \"/evaluate2.tsv\", sep='\\t')\n",
    "data4 = data4.sort_values('true_not_random')\n",
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "# plt.grid(linestyle='--', which='minor')\n",
    "ax.bar(data4['cat'], data4['true_not_random'], fill=False)\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.tick_params(labelsize=14)\n",
    "for i in range(28):\n",
    "    cat = rawset.ix_to_cat[i]\n",
    "    v = data4.iloc[i,3]\n",
    "    t = ax.annotate('%0.2f'%v, (i-0.3, v-0.06),fontsize=14)\n",
    "    t.set_rotation(90)\n",
    "# data3.plot.bar('cat', ['not_random'], figsize=(12,4))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.sum(data4['true_not_random'])/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(np.sum(data4['true_not_random'])+(1-0.62))/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
